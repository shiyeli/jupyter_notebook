{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型持久化文件介绍\n",
    "\n",
    "\n",
    "### 保存方式一\n",
    "\n",
    "#### 保存代码：\n",
    "```\n",
    "saver.save(sess,'./tmp/my_model/model.ckpt')\n",
    "```\n",
    "\n",
    "计算图结构（Meta graph）：\n",
    "model.ckpt-30001.meta \n",
    "\n",
    "最新版本模型和所有版本模型路径：\n",
    "checkpoint \n",
    "\n",
    "model.ckpt文件（Checkpoint file），保存所有的weights,biases,gradients和其他variables的值：\n",
    "\n",
    "model.ckpt-30001.data-00000-of-00001\n",
    "model.ckpt-30001.index\n",
    "\n",
    "\n",
    "```\n",
    "#恢复模型\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.import_meta_graph('path/to/model/model.meta')\n",
    "    new_saver.restore(sess,tf.train.latest_checkpoint('path/to/model/model.ckpt‘))\n",
    "    \n",
    "    #加载部分变量\n",
    "    graph = tf.get_default_graph()\n",
    "    fc7= graph.get_tensor_by_name('fc7:0')\n",
    "```\n",
    "**此种保存形式只能在Tensorflow框架下使用**\n",
    "\n",
    "### 保存方式二\n",
    "\n",
    ".pb格式文件\n",
    "\n",
    "#### 保存代码:\n",
    "```\n",
    "from tensorflow.python.framework import graph_util\n",
    "\n",
    "# convert_variables_to_constants 需要指定output_node_names，list()，可以多个\n",
    "constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph_def, ['op_to_store'])\n",
    "\n",
    "    # 测试 OP\n",
    "    feed_dict = {x: 10, y: 3}\n",
    "    print(sess.run(op, feed_dict))\n",
    "\n",
    "    # 写入序列化的 PB 文件\n",
    "    with tf.gfile.FastGFile(pb_file_path+'model.pb', mode='wb') as f:\n",
    "        f.write(constant_graph.SerializeToString())\n",
    "```\n",
    "\n",
    "#### 恢复模型：\n",
    "\n",
    "```\n",
    "#读取google训练好的模型classify_image_graph_def.pb\n",
    "inception_graph_def_file=os.path.join(LOG_DIR,'classify_image_graph_def.pb')\n",
    "with tf.Session() as sess:\n",
    "    #创建一个图来存放训练好的模型\n",
    "    with tf.gfile.FastGFile(inception_graph_def_file,'rb') as f:\n",
    "        graph_def=tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        tf.import_graph_def(graph_def,name='')\n",
    "        \n",
    "    #保存图结构：保存之前将之前保存的events.out.tfevents......iMac文件删除\n",
    "    #tools.delete_dir_file(LOG_DIR,'iMac')\n",
    "    \n",
    "    writer=tf.summary.FileWriter(LOG_DIR,sess.graph)\n",
    "    writer.close()\n",
    "\n",
    "```\n",
    "\n",
    "### [点击下载inception-v3.pd文件](http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz)\n",
    "数据解压之后有以下文件：\n",
    "\n",
    "* classify_image_graph_def.pb\n",
    "* imagenet_2012_challenge_label_map_proto.pbtxt\n",
    "* imagenet_synset_to_human_label_map.txt\n",
    "\n",
    "其中后面两个用于最后的分类显示，相当于网络最后一层softmax得出得分类是一个字符串，然后这个字符串在文件里面查找出对应的human_label.直接用inception-v3分类需要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#现在下载好inception-v3.pd文件，将其读入并保存计算图，\n",
    "#以便与使用tensorboard查看其结构\n",
    "#读取google训练好的模型classify_image_graph_def.pb\n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "INCEPTION_V3_PD='tmp/inception_v3/classify_image_graph_def.pb'\n",
    "INCEPTION_V3_GRAPH_DEF='tmp/inception_v3_graph_def'\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #创建一个图来存放训练好的模型\n",
    "    with tf.gfile.FastGFile(INCEPTION_V3_PD,'rb') as f:\n",
    "        graph_def=tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        tf.import_graph_def(graph_def,name='inception-v3')\n",
    "    \n",
    "    writer=tf.summary.FileWriter(INCEPTION_V3_GRAPH_DEF,sess.graph)\n",
    "    writer.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行后得到文件：\n",
    "\n",
    "events.out.tfevents.1530084131.c82682dd8be5\n",
    "\n",
    "执行下面命令便可查看模型结构：\n",
    "\n",
    "tensorboard --logdir=path/to/events.out.tfevents..._save_dir\n",
    "\n",
    "输入张量\n",
    "![](https://upload-images.jianshu.io/upload_images/1271438-12159ef39308d192.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n",
    "\n",
    "![](https://upload-images.jianshu.io/upload_images/1271438-a1fd3f34e2b40aa9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n",
    "\n",
    "# 接下来将进行的操作便是：\n",
    "构建一个自己的softmax全连接层，连接到张量pool_3/_reshape:0后面，以此实现迁移学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['flower_photos/sunflowers/11881770944_22b4f2f8f6_n.jpg',\n",
       "        'flower_photos/sunflowers/9783416751_b2a03920f7_n.jpg',\n",
       "        'flower_photos/sunflowers/2689228449_e0be72cf00_n.jpg',\n",
       "        'flower_photos/sunflowers/6606743797_c90c669757.jpg',\n",
       "        'flower_photos/dandelion/3844111216_742ea491a0.jpg'],\n",
       "       dtype='|S53'), array([[ 0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.]]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#获取数据\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "FLOWER_PHOTOS_PATH='flower_photos'\n",
    "TEST_ACCOUNT=1000\n",
    "\n",
    "\n",
    "def get_datasets():\n",
    "    sub_dirs=[_[0] for _ in os.walk(FLOWER_PHOTOS_PATH)][1:]\n",
    "    images=[]\n",
    "    \n",
    "    \"\"\"\n",
    "    flower_photos/daisy 0\n",
    "    flower_photos/dandelion 1\n",
    "    flower_photos/roses 2\n",
    "    flower_photos/sunflowers 3\n",
    "    flower_photos/tulips 4\n",
    "    \"\"\"\n",
    "    labels=[]\n",
    "    \n",
    "    for index,sub_dir in enumerate(sub_dirs):\n",
    "        file_names=glob.glob(sub_dir+'/*.jpg')\n",
    "        images.extend(file_names)\n",
    "        labels.extend(np.full(len(file_names),index))\n",
    "          \n",
    "    #乱序\n",
    "    state=np.random.get_state()\n",
    "    np.random.shuffle(images)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(labels)\n",
    "    \n",
    "    \"\"\"\n",
    "    ['flower_photos/tulips/3909355648_42cb3a5e09_n.jpg', \n",
    "    'flower_photos/tulips/5634767665_0ae724774d.jpg', \n",
    "    'flower_photos/dandelion/17482158576_86c5ebc2f8.jpg', \n",
    "    'flower_photos/tulips/16265876844_0a149c4f76.jpg',\n",
    "    'flower_photos/dandelion/344318990_7be3fb0a7d.jpg']\n",
    "    \"\"\"\n",
    "    return images,labels\n",
    "    \n",
    "images,labels=get_datasets()\n",
    "\n",
    "TRAIN_IMAGES,TRAIN_LABELS=images[TEST_ACCOUNT:],labels[TEST_ACCOUNT:]\n",
    "TEST_IMAGES,TEST_LABELS=images[:TEST_ACCOUNT],labels[:TEST_ACCOUNT]\n",
    "\n",
    "def get_batch(batch,train=True):\n",
    "    if train:\n",
    "        state=np.random.get_state()\n",
    "        images=np.random.choice(TRAIN_IMAGES,size=batch)\n",
    "        np.random.set_state(state)\n",
    "        labels=np.random.choice(TRAIN_LABELS,size=batch)\n",
    "    else:\n",
    "        images,labels=TEST_IMAGES,TEST_LABELS\n",
    "    one_hot=np.eye(NUM_CLASS)\n",
    "    labels=np.apply_along_axis(lambda x:one_hot[x],0,labels)\n",
    "    return images,labels\n",
    "\n",
    "get_train_batch(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#迁移网络结构-向前传播\n",
    "import tensorflow as tf\n",
    "\n",
    "DECODE_JEPG_CONTENTS='DecodeJepg/contents:0'\n",
    "POOL_3_RESHAPE_NAME='pool_3/_reshape:0'\n",
    "POOL_3_RESHAPE_NODE=2048\n",
    "\n",
    "MIDDLE_NODE=500\n",
    "NUM_CLASS=5\n",
    "\n",
    "LEARNING_RATE=0.0001\n",
    "STEPS=300\n",
    "BATCH=32\n",
    "\n",
    "\"\"\"\n",
    "inception-v3的输入是图片raw data,对应的y为 [1 0 0 0 0]\n",
    "\"\"\"\n",
    "\n",
    "def inference_custom(pool3_reshape_values):\n",
    "    \n",
    "    #输入为pool3_reshape_tensor,shape:[1,2048]\n",
    "    \n",
    "    #自定义全连接层一\n",
    "    with tf.variable_scope('custom_layer_1'):\n",
    "        cl1_weights=tf.get_variable(\n",
    "            'weights',\n",
    "            [2048,MIDDLE_NODE],\n",
    "            initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "        )\n",
    "        \n",
    "        cl1_biases=tf.get_variable(\n",
    "            'biases',\n",
    "            [MIDDLE_NODE],\n",
    "            initializer=tf.constant_initializer(0.1)\n",
    "        )\n",
    "    \n",
    "        cl1=tf.nn.relu(tf.matmul(pool3_reshape_values,cl1_weights)+cl1_biases)\n",
    "    \n",
    "    #自定义全连接层二\n",
    "    with tf.variable_scope('custom_layer_2'):\n",
    "        cl2_weights=tf.get_variable(\n",
    "            'weights',\n",
    "            [2048,NUM_CLASS],\n",
    "            initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "        )\n",
    "        \n",
    "        cl2_biases=tf.get_variable(\n",
    "            'biases',\n",
    "            [NUM_CLASS],\n",
    "            initializer=tf.constant_initializer(0.1)\n",
    "        )\n",
    "    \n",
    "        logit=tf.matmul(cl1,cl2_weights)+cl2_biases\n",
    "    \n",
    "    return logit\n",
    "\n",
    "def get_pool3_reshape_values(sess,pool3_reshape_tensor,images_data):\n",
    "    \n",
    "    pool3_reshape_values=sess.run(pool3_reshape_tensor,feed_dict={\n",
    "        DECODE_JEPG_CONTENTS:images_data\n",
    "    })\n",
    "    return pool3_reshape_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Requested return_element 'DecodeJepg/contents:0' not found in graph_def.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-c2b08dfe15a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mflags_passthrough\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-c2b08dfe15a6>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-c2b08dfe15a6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         decode_jepg_contents_tensor,pool_3_reshape_tensor=tf.import_graph_def(\n\u001b[1;32m     16\u001b[0m             \u001b[0mgraph_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             return_elements=[DECODE_JEPG_CONTENTS,POOL_3_RESHAPE_NAME])\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#输入变量初始化\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.pyc\u001b[0m in \u001b[0;36mimport_graph_def\u001b[0;34m(graph_def, input_map, return_elements, name, op_dict, producer_op_list)\u001b[0m\n\u001b[1;32m    524\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             raise ValueError(\n\u001b[0;32m--> 526\u001b[0;31m                 'Requested return_element %r not found in graph_def.' % name)\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Requested return_element 'DecodeJepg/contents:0' not found in graph_def."
     ]
    }
   ],
   "source": [
    "#迁移网络结构-训练部分\n",
    "\n",
    "MODE_SAVE_PATH='tmp/transer/model.ckpt'\n",
    "\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "def train():\n",
    "    \n",
    "    #读取inception-v3.pd\n",
    "    INCEPTION_V3_PD='tmp/inception_v3/classify_image_graph_def.pb'\n",
    "    with tf.gfile.FastGFile(INCEPTION_V3_PD,'rb') as f:\n",
    "        graph_def=tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "        decode_jepg_contents_tensor,pool_3_reshape_tensor=tf.import_graph_def(\n",
    "            graph_def,\n",
    "            return_elements=[DECODE_JEPG_CONTENTS,POOL_3_RESHAPE_NAME])\n",
    "\n",
    "    #输入变量初始化\n",
    "    x=tf.placeholder(tf.float32,[None,POOL_3_RESHAPE_NODE])\n",
    "    y_=tf.placeholder(tf.float32,[None,NUM_CLASS],name='y-input')\n",
    "    \n",
    "    #向前传播\n",
    "    y=inference_custom(x)\n",
    "    global_step=tf.Variable(0,trainable=False)\n",
    "\n",
    "    cross_entropy=tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=y,\n",
    "        labels=tf.argmax(y_,1)\n",
    "    )\n",
    "    \n",
    "    loss=tf.reduce_mean(cross_entropy)\n",
    "    train_step=tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(loss,global_step=global_step)\n",
    "    \n",
    "    saver=tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for i in range(STEPS):\n",
    "            xs,ys=get_train_batch(BATCH)\n",
    "            xs_raw_data=gfile.FastGFile(xs,'rb').read()\n",
    "            pool3_reshape_values=get_pool3_reshape_values(sess,pool_3_reshape_tensor,xs_raw_data)\n",
    "            \n",
    "            loss,step=sess.run([loss,global_step],feed_dict={\n",
    "                x:pool3_reshape_values,\n",
    "                y_:ys   \n",
    "            })\n",
    "            \n",
    "            if i% 20==0:\n",
    "                print 'Step:%d, loss=%f' % (step,loss)\n",
    "            \n",
    "            #保存模型\n",
    "            saver.save(sess,MODE_SAVE_PATH,global_step=step)\n",
    "\n",
    "def main(argv=None):\n",
    "    train()\n",
    "    \n",
    "    \n",
    "if __name__=='__main__':\n",
    "    tf.app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
